Sousgrad <- function(f,domain,x0,t0) {
x_k <- x0 #point courant
t_k <- t0 #pas courant
k <- 0 #nombre d'iterations
while (TRUE) {    #calcul du sous-gradient
g <- approxfun(f,domain)    # crée une fonction linéaire
dg <- D(g,"x")    #calcule de la derivée de dg
g_k <- dg(x_k) #calcul le sous-gradient au point x_k
# Mise à jour du point courant
x_k <- x_k - t_k * g_k # Met à jour le point courant
x_k <- min(max(x_k, domain1), domain2)# Le projette sur le domaine
# Mise à jour du pas
k <- k + 1 # Incrémente le nombre d’itérations
t_k <- t0 / sqrt(k) # Met à jour le pas
# Critère d’arrêt
if (abs(g_k) < 1e-6 || abs(f(x_k) - f(x_k-1)) < 1e-6 || k > 1000)
{ break # Sort de la boucle
}
}
return(x_k) # Retourne le résultat
cat("La valeur minimale de la fonction est", f(x_k), "au point", x_k, "\n") # Affiche la valeur minimale
cat("Le nombre d’itérations effectuées est", k, "\n") # Affiche le nombre d’itérations
}
v <- 1
s <- 1
sum <- 0
somme_positive <- function(v){
for (i in n) {
if s[i]>0 then
sum_positive_numbers <- function(vector) {
sum(vector[vector > 7])
}
somme_positive <- function(v){
if v[i]>0 then
install.packages("devtools")
# Mise à jour du point courant
x_k <- x_k - t_k * g_k # Met à jour le point courant
Sousgrad <- function(f,domain,x0,t0) {
x_k <- x0 #point courant
t_k <- t0 #pas courant
k <- 0 #nombre d'iterations
while (TRUE) {    #calcul du sous-gradient
g <- approxfun(f,domain)    # crée une fonction linéaire
dg <- D(g,"x")    #calcule de la derivée de dg
g_k <- dg(x_k) #calcul le sous-gradient au point x_k
# Mise à jour du point courant
x_k <- x_k - t_k * g_k # Met à jour le point courant
x_k <- min(max(x_k, domain1), domain2)# Le projette sur le domaine
# Mise à jour du pas
k <- k + 1 # Incrémente le nombre d’itérations
t_k <- t0 / sqrt(k) # Met à jour le pas
# Critère d’arrêt
if (abs(g_k) < 1e-6 || abs(f(x_k) - f(x_k-1)) < 1e-6 || k > 1000)
{ break # Sort de la boucle
}
}
return(x_k) # Retourne le résultat
cat("La valeur minimale de la fonction est", f(x_k), "au point", x_k, "\n") # Affiche la valeur minimale
cat("Le nombre d’itérations effectuées est", k, "\n") # Affiche le nombre d’itérations
}
install.packages("rtools")
install.packages(c("devtools", "usethis", "roxygen2"))
Sousgrad <- function(f,domain,x0,t0) {
x_k <- x0 #point courant
t_k <- t0 #pas courant
k <- 0 #nombre d'iterations
while (TRUE) {    #calcul du sous-gradient
g <- approxfun(f,domain)    # crée une fonction linéaire
dg <- D(g,"x")    #calcule de la derivée de dg
g_k <- dg(x_k) #calcul le sous-gradient au point x_k
# Mise à jour du point courant
x_k <- x_k - t_k * g_k # Met à jour le point courant
x_k <- min(max(x_k, domain1), domain2)# Le projette sur le domaine
# Mise à jour du pas
k <- k + 1 # Incrémente le nombre d’itérations
t_k <- t0 / sqrt(k) # Met à jour le pas
# Critère d’arrêt
if (abs(g_k) < 1e-6 || abs(f(x_k) - f(x_k-1)) < 1e-6 || k > 1000)
{ break # Sort de la boucle
}
}
return(x_k) # Retourne le résultat
cat("La valeur minimale de la fonction est", f(x_k), "au point", x_k, "\n") # Affiche la valeur minimale
cat("Le nombre d’itérations effectuées est", k, "\n") # Affiche le nombre d’itérations
}
usethis::use_testthat()
sousgrad_plot<- function(objective){
iteration <-seq_along(fonction_objective) #creation de la sequence d'iteration
plot(iteration,fonction_objective,type="1",xlab="iteration",ylab="valeur de l'objectif",
main="courbe de  convergence de la fonction objective")
}
View(sousgrad_plot)
plot(iteration,fonction_objective,type="1",xlab="iteration",ylab="valeur de l'objectif",
main="courbe de  convergence de la fonction objective")
function(objective){
iteration <-seq_along(fonction_objective) #creation de la sequence d'iteration
plot(iteration,fonction_objective,type="1",xlab="iteration",ylab="valeur de l'objectif",
main="courbe de  convergence de la fonction objective")
}
function(objective){
iteration <-seq_along(fonction_objective) #creation de la sequence d'iteration
plot(iteration,fonction_objective,type="1",xlab="iteration",ylab="valeur de l'objectif",
main="courbe de  convergence de la fonction objective")
}
View(browseURL)
View(bibentry)
force(as.relistable)
#fonction d'entrainement du reseau de neurone avec l'algorithme du sous gradient
train_neuronal_network<- function(image,labels,num_epochs,learning_rate){
#initialisation des poids et biais avec des valeurs aléatoires
weights<-runif(ncol(image))
biais<- runif(1)
# boucle d'entrainement sur le nombre d'epoque
for (epoch in 1:num_epochs) {
#calcul de la propagation avant et calcul de la prediction
predictions<- predict_neuronal_network(image,weights,biais)
#calcul de la perte avec la fonction perte avec l'entropie
loss<-mean_squared_error(predictions,labels)
#calcul du sous gradient de la fonction perte
Sousgrad(loss)
}
}
library(askpass)
library(askpass)
